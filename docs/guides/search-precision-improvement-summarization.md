# 検索精度向上：要約アプローチ改善ロジック

## 概要

検索精度を向上させるため、記事本文を要約してからエンベディング生成を行うアプローチを実装します。

## Vectorizeインデックス

### v2インデックスの作成

評価のため、既存のベクトルストレージ（`kusoogle-articles`）は残し、新しいv2インデックス（`kusoogle-articles-v2`）を作成して切り替えました。

- **既存インデックス**: `kusoogle-articles`（比較用に保持）
- **新規インデックス**: `kusoogle-articles-v2`（要約アプローチ評価用）

### インデックスの切り替え方法

v2インデックスに切り替えるには、`wrangler.toml`で以下の設定を使用します：

```toml
[[vectorize]]
binding = "VECTORIZE_INDEX"
index_name = "kusoogle-articles-v2"
```

既存インデックスに戻す場合は：

```toml
[[vectorize]]
binding = "VECTORIZE_INDEX"
index_name = "kusoogle-articles"
```

### 比較評価

両方のインデックスで同じ検索クエリを実行し、結果を比較することで、要約アプローチの効果を測定できます。

## 現在の問題点

### 1. 長文記事の意味の平均化

**現状**:
- 記事全体（タイトル + タグ + 本文）をそのままエンベディング化
- 長文記事（3000文字以上）の場合、重要な情報が埋もれる
- 意味が平均化され、検索精度が低下

**例**:
```
記事: 5000文字の長文
→ エンベディング生成時に全体の平均的な意味が抽出される
→ 「Cloudflare Workers 非公開設定」という具体的な検索クエリにマッチしにくい
```

### 2. 非対称検索の課題

**現状**:
- 検索クエリ: 短い（例: "非公開 Workers"）
- ドキュメント: 長い（例: 5000文字の記事）
- この非対称性により、検索精度が低下

### 3. ノイズの混入

**現状**:
- 記事本文に含まれる余分な情報（挨拶、背景説明など）がエンベディングに含まれる
- 技術的な核心部分が埋もれる

## 改善アプローチ：要約による意味の凝縮

### 基本方針

1. **記事本文を要約**してからエンベディング生成
2. 要約には**技術的なキーワードと主要な手順を必ず含める**
3. タイトル + タグ + 要約でエンベディング生成

### 設計

#### 1. 要約生成

**モデル**: `@cf/meta/llama-3.1-8b-instruct`（Cloudflare AI Workers）

**要約プロンプト設計**:
```
技術記事を400文字以内で要約してください。

以下の情報を必ず含めてください：
- 使用技術・ツール名（例: Cloudflare Workers, Next.js, TypeScript）
- 主要な手順や設定方法
- エラー解決方法（該当する場合）
- コードブロックの内容は簡潔に説明（コード自体は含めない）

技術的なキーワードは省略せず、正確に含めてください。
```

**要約の長さ**: 400文字以内（トークン数で約200-300トークン）

**理由**:
- エンベディングモデルの最適な入力長に合わせる
- 意味を凝縮しつつ、重要な情報を保持

#### 2. エンベディング生成

**変更前**:
```typescript
const text = `${article.title}\n${tagsText}\n${article.body}`;
```

**変更後**:
```typescript
const summary = await summarizeArticle(article.body, ai, 400);
const text = `タイトル: ${article.title}\nタグ: ${tagsText}\n要約: ${summary}`;
```

**メタデータ構造**:
- タイトル: そのまま使用
- タグ: そのまま使用
- 要約: 新規追加（エンベディング生成にのみ使用、保存しない）

#### 3. データフロー

```
Qiita API
  ↓
記事取得（タイトル、タグ、本文）
  ↓
要約生成（LLM）
  ↓
エンベディング生成（タイトル + タグ + 要約）
  ↓
Vectorizeに保存（ベクトルのみ、要約は保存しない）
```

## 実装手順

### STEP 1: 要約関数の実装

**ファイル**: `packages/shared/src/utils/text.ts`

**実装内容**:
- `summarizeArticle`関数を追加
- Cloudflare AI WorkersのLLMを使用して要約生成

**関数シグネチャ**:
```typescript
export async function summarizeArticle(
  body: string,
  ai: Ai,
  maxLength: number = 400
): Promise<string>
```

### STEP 2: エンベディング生成の修正

**ファイル**: `apps/workers/data-collection/src/utils/embedding.ts`

**変更内容**:
1. `summarizeArticle`をインポート
2. `generateEmbedding`関数内で要約生成を追加
3. タイトル + タグ + 要約でエンベディング生成

### STEP 3: エラーハンドリング

**実装内容**:
- 要約生成失敗時のフォールバック（元の本文を使用）
- タイムアウト処理
- リトライロジック

### STEP 4: テスト・検証

**検証項目**:
1. 要約品質の確認
   - 技術キーワードが含まれているか
   - 主要な手順が含まれているか
   - 400文字以内に収まっているか

2. 検索精度の改善確認
   - 改善前後の検索結果を比較
   - 具体的なクエリでテスト

3. パフォーマンス確認
   - 要約生成の処理時間
   - エンベディング生成の処理時間
   - 全体の処理時間への影響

## 期待される効果

### 1. 検索精度の向上

**改善前**:
- 長文記事の意味が平均化され、具体的な検索クエリにマッチしにくい

**改善後**:
- 要約により意味が凝縮され、重要な情報が強調される
- 技術キーワードが明確になり、検索精度が向上

### 2. ノイズの削減

**改善前**:
- 余分な情報（挨拶、背景説明など）がエンベディングに含まれる

**改善後**:
- 要約により技術的な核心部分のみが抽出される
- ノイズが削減され、検索精度が向上

### 3. 非対称検索の改善

**改善前**:
- 短いクエリ vs 長いドキュメントの非対称性

**改善後**:
- 要約によりドキュメントが短縮され、非対称性が緩和

## 測定方法

### 1. 要約品質の測定

**指標**:
- 技術キーワードの含有率
- 要約の長さ（400文字以内）
- 人間による評価（サンプル記事で確認）

### 2. 検索精度の測定

**テストクエリ例**:
- "Cloudflare Workers 非公開"
- "Next.js Server Actions"
- "TypeScript 型エラー"
- "エラーハンドリング"

**測定方法**:
1. 改善前後の検索結果を比較
2. 関連記事が上位に表示されるか確認
3. 類似度スコアの変化を確認

### 3. パフォーマンスの測定

**指標**:
- 要約生成時間（平均、最大）
- エンベディング生成時間（平均、最大）
- 全体の処理時間への影響

## コスト影響

### Cloudflare AI Workers

**要約生成**:
- モデル: `@cf/meta/llama-3.1-8b-instruct`
- 1記事あたり: 1回のLLM呼び出し
- 無料枠内で対応可能（1日あたりのリクエスト数に制限あり）

**エンベディング生成**:
- モデル: `@cf/baai/bge-base-en-v1.5`
- 変更なし（1記事あたり1回）

**総コスト**:
- 初期データ取得時: 記事数 × 2回のAPI呼び出し（要約 + エンベディング）
- 日次更新時: 新規記事数 × 2回のAPI呼び出し

## リスクと対策

### 1. 要約品質のばらつき

**リスク**:
- LLMによる要約の品質が記事によって異なる
- 重要な情報が省略される可能性

**対策**:
- プロンプトを最適化（技術キーワードを必ず含める指示）
- 要約品質のサンプルチェック
- 必要に応じてプロンプトを調整

### 2. 処理時間の増加

**リスク**:
- 要約生成により処理時間が増加
- 初期データ取得に時間がかかる

**対策**:
- 要約生成は非同期で処理
- エラーハンドリングでフォールバック（元の本文を使用）
- 必要に応じて並列処理を検討

### 3. コストの増加

**リスク**:
- LLM呼び出しが追加され、コストが増加

**対策**:
- Cloudflare AI Workersの無料枠内で対応
- 必要に応じてレート制限を実装

## フォールバック戦略

### 要約生成失敗時

**処理**:
1. 要約生成が失敗した場合、元の本文を使用
2. エラーログを記録
3. 処理を継続（エンベディング生成は実行）

**実装**:
```typescript
try {
  const summary = await summarizeArticle(article.body, ai, 400);
  text = `タイトル: ${article.title}\nタグ: ${tagsText}\n要約: ${summary}`;
} catch (error) {
  console.error('要約生成に失敗しました。元の本文を使用します:', error);
  text = `${article.title}\n${tagsText}\n${article.body}`;
}
```

## 今後の拡張案

### 1. チャンキングとの併用

要約アプローチで効果が不十分な場合、チャンキングと併用することを検討：
- 要約版エンベディング（全体の意味把握）
- チャンク版エンベディング（詳細情報の検索）

### 2. クエリ拡張

検索クエリを意味拡張してから検索：
- 短文クエリを複数の関連クエリに展開
- 複数クエリで検索して結果を統合

### 3. エンベディングモデルの変更

`@cf/baai/bge-base-en-v1.5` → `@cf/baai/bge-large-en-v1.5`への変更を検討：
- 非対称検索の精度向上
- Vectorizeインデックスの再作成が必要

## 実装チェックリスト

- [ ] 要約関数の実装（`packages/shared/src/utils/text.ts`）
- [ ] エンベディング生成の修正（`apps/workers/data-collection/src/utils/embedding.ts`）
- [ ] エラーハンドリングの実装
- [ ] 型定義の追加（`Ai`型のインポート）
- [ ] テスト・検証
- [ ] 要約品質の確認
- [ ] 検索精度の改善確認
- [ ] パフォーマンスの確認
- [ ] ドキュメントの更新

## 参考資料

- [Cloudflare AI Workers Documentation](https://developers.cloudflare.com/workers-ai/)
- [BGE Embedding Models](https://huggingface.co/BAAI/bge-base-en-v1.5)
- [Semantic Search Best Practices](https://www.pinecone.io/learn/semantic-search/)

